{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Header-->\n",
    "<div>\n",
    "    <div class=\"row\" style=\"color: #4D4D4D;font-size: 15px;padding-bottom: 20px\">\n",
    "        <div class=\"col-md-7\">\n",
    "            <img src=\"http://materials.cv.uoc.edu/cdocent/common/img/logo-uoc.png\" alt=\"Logo UOC\" class=\"img-responsive\" style=\"margin:20px 0px 0px\">\n",
    "        </div>\n",
    "        <div class=\"col-md-5\">\n",
    "            <h1 style=\"margin:15px 0px 0px;font-size: 40px;\">Avaluació de models de classificació</h1>\n",
    "            <div style=\"text-align:left;margin-top: 5px;\"></div>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div class=\"row\" style=\"background: #FCB517;padding: 10px 20px;\">\n",
    "        <div class=\"col-md-6\">\n",
    "            <div>PID_00233252</div>\n",
    "        </div>\n",
    "        <div class=\"col-md-6\">\n",
    "            <div style=\"text-align:right;\">Autor: Xavier Duran Albareda <span style=\"margin-left: 30px;\">Coordinació: Julià Minguillón</span></div>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "<!--/Header-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducció"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els problemes de classificació són un dels més comuns dins de l'aprenentatge automàtic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [model_evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- [hyperparameters-and-model-validation](https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html)\n",
    "- [evaluation](http://magizbox.com/training/machinelearning/site/evaluation/)\n",
    "- [how-to-predict-telco-churn-with-apache-spark-mllib](https://blog.cloudera.com/blog/2016/02/how-to-predict-telco-churn-with-apache-spark-mllib/)\n",
    "- [evaluating-a-machine-learning-model](https://www.jeremyjordan.me/evaluating-a-machine-learning-model/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mètriques per avaluar un model de classificació\n",
    "\n",
    "Al llarg del temps s'han desenvolupat moltes mètriques per avaluar la qualitat d'aquests models de classificació, i fer-ne servir una o una altra dependrà molt de l'apliació concreta que en volguem fer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exactitud\n",
    "\n",
    "L'exactitud o _accuracy_ és la proporció d'exemples que s'han classificat correctament, o el que és el mateix, en que la categoria que ha predit el nostre model coincideix amb la categoria correcta.\n",
    "\n",
    "L'avantatge d'aquesta mesura és que és molt senzilla d'entendre, però té moltes limitacions, ja que dóna una visió massa simple del que realment està fent el model. A continuació veurem altres mètriques més complexes i quina motivació tenim per fer-les servir per millorar la nostra visió del que està fent el nostre model en un conjunt de dades determinat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy is the number of correct predictions made as a ratio of all predictions made.\n",
    "\n",
    "This is the most common evaluation metric for classification problems, it is also the most misused. It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case.\n",
    "\n",
    "Below is an example of calculating classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770 (0.048)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f (%.3f)\") % (results.mean(), results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriu de confusió"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is a handy presentation of the accuracy of a model with two or more classes.\n",
    "\n",
    "The table presents predictions on the x-axis and accuracy outcomes on the y-axis. The cells of the table are the number of predictions made by a machine learning algorithm.\n",
    "\n",
    "For example, a machine learning algorithm can predict 0 or 1 and each prediction may actually have been a 0 or 1. Predictions for 0 that were actually 0 appear in the cell for prediction=0 and actual=0, whereas predictions for 0 that were actually 1 appear in the cell for prediction = 0 and actual=1. And so on.\n",
    "\n",
    "You can learn more about the Confusion Matrix on the Wikipedia article.\n",
    "\n",
    "Below is an example of calculating a confusion matrix for a set of prediction by a model on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Àrea sota la corba ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area under ROC Curve (or AUC for short) is a performance metric for binary classification problems.\n",
    "\n",
    "The AUC represents a model’s ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random. Learn more about ROC here.\n",
    "\n",
    "ROC can be broken down into sensitivity and specificity. A binary classification problem is really a trade-off between sensitivity and specificity.\n",
    "\n",
    "Sensitivity is the true positive rate also called the recall. It is the number instances from the positive (first) class that actually predicted correctly.\n",
    "Specificity is also called the true negative rate. Is the number of instances from the negative class (second) class that were actually predicted correctly.\n",
    "You can learn more about ROC on the Wikipedia page.\n",
    "\n",
    "The example below provides a demonstration of calculating AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification ROC AUC\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: %.3f (%.3f)\") % (results.mean(), results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informe de classificació"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn does provide a convenience report when working on classification problems to give you a quick idea of the accuracy of a model using a number of measures.\n",
    "\n",
    "The classification_report() function displays the precision, recall, f1-score and support for each class.\n",
    "\n",
    "The example below demonstrates the report on the binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.87      0.82       162\n",
      "        1.0       0.71      0.55      0.62        92\n",
      "\n",
      "avg / total       0.75      0.76      0.75       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Report\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "report = classification_report(Y_test, predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusió\n",
    "\n",
    "En aquesta activitat hem vist algunes de les visualitzacions més comunes i exemples de com implementar-les en les llibreries `Matplotlib` i `Seaborn`. Una de les qüestions clau per seleccionar el model és escollir una bona mètrica d'avaluació del model que ens indiqui quin serà el rendiment d'aquest en l'àmbit en que l'aplicarem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Footer-->\n",
    " <div style=\"background: #333333;padding: 35px 0px;margin-top: 25px;\">\n",
    "    <div class=\"row\">\n",
    "     <div class=\"col-sm-12\">\n",
    "        <img src=\"http://materials.cv.uoc.edu/cdocent/common/img/logo-uoc-bottom.png\" alt=\"Logo UOC\" class=\"img-responsive\" style=\"margin: 0 auto; display: block;\">\n",
    "    </div>\n",
    "</div>\n",
    "</div>\n",
    "<!--/Footer-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
